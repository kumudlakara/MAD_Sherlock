{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.data import get_data_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../../datasets/finetuning_dataset/val.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_path(ann):\n",
    "    visual_news_data = json.load(open(\"../../datasets/visualnews/origin/data.json\"))\n",
    "    visual_news_data_mapping = {ann[\"id\"]: ann for ann in visual_news_data}\n",
    "\n",
    "\n",
    "    caption = visual_news_data_mapping[ann[\"id\"]][\"caption\"]\n",
    "    image_path = visual_news_data_mapping[ann[\"image_id\"]][\"image_path\"]\n",
    "    image_path = \"./visualnews/origin/\"+image_path[2:]\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/5356 [00:53<7:13:06,  4.86s/it]"
     ]
    }
   ],
   "source": [
    "ready_dataset = []\n",
    "for dp in tqdm(data):\n",
    "    true_ann, false_ann = dp['true_ann'], dp['false_ann']\n",
    "    data_dict = {}\n",
    "    _, true_cap = get_data_elements(true_ann)\n",
    "    _, false_cap = get_data_elements(false_ann)\n",
    "    data_dict[\"id\"] = str(true_ann[\"id\"])+\"_\"+str(false_ann['id'])\n",
    "    data_dict[\"image\"] = get_img_path(dp['true_ann'])\n",
    "    data_dict[\"conversations\"] = [\n",
    "      {\n",
    "        \"from\": \"human\",\n",
    "        \"value\": \"\"\"<image>\\nYou are given two captions for the given image. One caption is True and the other is False.\n",
    "                Based on the image, your task is to identify the most obvious element of inconsistency (MUST BE ONE WORD) such as location, time, event, person, organisation etc. in the two captions.\n",
    "                TRUE CAPTION: {}\n",
    "                FALSE CAPTION: {}\n",
    "\n",
    "                You must respond by filling the following template as accurately as possible. \n",
    "                Be as concise as possble.\n",
    "                <template>\n",
    "                The two captions are inconsistent in: <element>. \n",
    "                The <element> in the false caption is: <false_entity>.\n",
    "                However, the <element> which the true caption and image correspond to is: <true_entity>\n",
    "                </template>\"\"\".format(true_cap, false_cap)\n",
    "      },\n",
    "      {\n",
    "        \"from\": \"gpt\",\n",
    "        \"value\": \"\"\"The two captions are inconsistent in: {}. \n",
    "                The {} in the false caption is: {}.\n",
    "                However, the {} which the true caption and image correspond to is: {}\"\"\".format(dp['inconsistent_entity'], dp['inconsistent_entity'],dp['false_entity'],dp['inconsistent_entity'], dp['true_entity'])\n",
    "      },\n",
    "    ]\n",
    "    ready_dataset.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '92318_136816',\n",
       " 'image': '../../datasets/visualnews/origin/washington_post/images/0218/348.jpg',\n",
       " 'conversations': [{'from': 'human',\n",
       "   'value': '<image>\\nYou are given two captions for the given image. One caption is True and the other is False.\\n                Based on the image, your task is to identify the most obvious element of inconsistency (MUST BE ONE WORD) such as location, time, event, person, organisation etc. in the two captions.\\n                TRUE CAPTION: People walk in the parking lot of an Ikea store in Brooklyn\\n                FALSE CAPTION: An an armed suspect shot an armored car guard during a robbery in the Oxon Hill area of Prince George s County authorities said\\n\\n                You must respond by filling the following template as accurately as possible. \\n                Be as concise as possble.\\n                <template>\\n                The two captions are inconsistent in: <element>. \\n                The <element> in the false caption is: <false_entity>.\\n                However, the <element> which the true caption and image correspond to is: <true_entity>\\n                </template>'},\n",
       "  {'from': 'gpt',\n",
       "   'value': \"The two captions are inconsistent in: location. \\n                The location in the false caption is: Brooklyn.\\n                However, the location which the true caption and image correspond to is: Oxon Hill area of Prince George's County\"}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ready_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./../../datasets/finetuning_dataset/val.json\", \"w\") as f:\n",
    "    json.dump(ready_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiments",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
